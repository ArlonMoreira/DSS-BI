{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Leitura do dataset - 50.000 textos rotulados em positivo e negativo\n",
    "\n",
    "dataset = pd.read_csv(r'movie_reviews.csv')\n",
    "\n",
    "\n",
    "#Visualização dos títulos das colunas\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisão do dataset em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[:35000] #35.000 para treino\n",
    "test_data = dataset[35000:] #15.00 para teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = np.array(test_data['review'])\n",
    "test_sentiments = np.array(test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma amostragem para facilitar o estudo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Worst movie, (with the best reviews given it) I've ever seen. Over the top dialog, acting, and direction. more slasher flick than thriller.With all the great reviews this movie got I'm appalled that it turned out so silly. shame on you martin scorsese\",\n",
       "  'negative'),\n",
       " ('I hope this group of film-makers never re-unites.', 'negative'),\n",
       " ('no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!',\n",
       "  'negative'),\n",
       " ('Add this little gem to your list of holiday regulars. It is<br /><br />sweet, funny, and endearing',\n",
       "  'positive'),\n",
       " ('a mesmerizing film that certainly keeps your attention... Ben Daniels is fascinating (and courageous) to watch.',\n",
       "  'positive'),\n",
       " ('This movie is perfect for all the romantics in the world. John Ritter has never been better and has the best line in the movie! \"Sam\" hits close to home, is lovely to look at and so much fun to play along with. Ben Gazzara was an excellent cast and easy to fall in love with. I\\'m sure I\\'ve met Arthur in my travels somewhere. All around, an excellent choice to pick up any evening.!:-)',\n",
       "  'positive'),\n",
       " (\"I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.\",\n",
       "  'positive'),\n",
       " ('Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbeliaveble but you have to see it really!!!! P.s watch the carrot',\n",
       "  'positive')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs = [100, 5817, 7626, 7356, 1008, 7155, 3533, 13010]\n",
    "sample_data = [(test_reviews[index],\n",
    "                test_sentiments[index])\n",
    "                  for index in sample_docs]\n",
    "\n",
    "\n",
    "sample_data        \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    " \n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    " \n",
    "def penn_to_wn(tag):\n",
    "\n",
    "    #Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    " \n",
    " \n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"<br />\", \" \")\n",
    "    #text = text.decode(\"utf-8\")\n",
    " \n",
    "    return text\n",
    " \n",
    " \n",
    "def swn_polarity(text):\n",
    "    \n",
    "    #Return a sentiment polarity: 0 = negative, 1 = positive\n",
    "    \n",
    " \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    " \n",
    "    text = clean_text(text)\n",
    " \n",
    " \n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    for raw_sentence in raw_sentences:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    " \n",
    "        for word, tag in tagged_sentence:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    " \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    " \n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    " \n",
    "            # Take the first sense, the most common\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    " \n",
    "            sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "            tokens_count += 1\n",
    " \n",
    "    # judgment call ? Default to positive or negative\n",
    "    if not tokens_count:\n",
    "        return 0\n",
    " \n",
    "    # sum greater than 0 => positive sentiment\n",
    "    if sentiment >= 0:\n",
    "        return 'positive'\n",
    " \n",
    "    # negative sentiment\n",
    "    return 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive negative\n",
      "positive positive\n",
      "positive negative\n",
      "positive positive\n",
      "negative positive\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print(swn_polarity(test_reviews[0]), test_sentiments[0]) #positive negative\n",
    "print(swn_polarity(test_reviews[1]), test_sentiments[1]) #positive positive\n",
    "print(swn_polarity(test_reviews[2]), test_sentiments[2]) #positive negative\n",
    "print(swn_polarity(test_reviews[3]), test_sentiments[3]) #positive positive\n",
    "print(swn_polarity(test_reviews[4]), test_sentiments[4]) #negative positive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668933333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred_y = [swn_polarity(text) for text in test_reviews]\n",
    " \n",
    "print(accuracy_score(test_sentiments, pred_y)) # 0.6689333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5429, 2081],\n",
       "       [2885, 4605]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_sentiments, pred_y, labels=[\"positive\", \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
