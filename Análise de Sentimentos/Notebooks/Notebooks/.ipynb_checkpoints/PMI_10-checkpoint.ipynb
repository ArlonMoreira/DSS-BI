{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar as bibliotecas necessarias de acordo com a vers√£o python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info[0] == 3:\n",
    "    from urllib.request import urlopen\n",
    "    from urllib.parse import urlencode\n",
    "else:\n",
    "    # Not Python 3 - today, it is most likely to be Python 2\n",
    "    # But note that this might need an update when Python 4\n",
    "    # might be around one day\n",
    "    from urllib import urlopen\n",
    "    from urllib import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input: Nokia is a amazing phone\n",
      "\n",
      "\n",
      "split version of input: ['Nokia', 'is', 'a', 'amazing', 'phone']\n",
      "\n",
      "\n",
      "POS tagged text: \n",
      "('Nokia', 'NNP') \n",
      "('is', 'VBZ') \n",
      "('a', 'DT') \n",
      "('amazing', 'JJ') \n",
      "('phone', 'NN') \n",
      "\n",
      "\n",
      "Extracting the tags alone: \n",
      "['NNP', 'DT', 'NN', 'VBZ', 'DT', 'JJ', 'NN', 'NNP', 'VBZ', 'VBZ', 'DT', 'DT', 'JJ', 'JJ', 'NN']\n",
      "Checking whether the tags conform to the required pattern...\n",
      "\n",
      "\n",
      "['Nokia', 'is', 'a', 'amazing', 'phone']\n",
      "['NNP', 'NN', 'DT', 'NN', 'VBZ', 'DT', 'JJ', 'NN']\n",
      "The extracted two-word phrases which satisfy the required pattern are:\n",
      "['NNP', 'NN', 'DT', 'NN', 'VBZ', 'DT', 'JJ', 'NN']\n",
      "['Nokia', 'is', 'a', 'amazing', 'phone']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-afe201a716ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#print(\"PMI - Pointwise Mutual Information\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#print(\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mstrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nokia is a amazing phone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;31m#print(strr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m#x = so(strr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-afe201a716ab>\u001b[0m in \u001b[0;36mtext_pos\u001b[0;34m(raw)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The extracted two-word phrases which satisfy the required pattern are:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mstrr1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrr1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-afe201a716ab>\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(newl, spl1)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"JJ\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"NN\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"JJ\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"NNS\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspl1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"NN\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"JJ\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"NN\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"NNS\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"NNS\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"JJ\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"NN\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnewl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"NNS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import bigrams\n",
    "import copy\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.data\n",
    "import json\n",
    "from math import log\n",
    "import itertools\n",
    "\n",
    "\n",
    "def hits(word1,word2=\"\"): #\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    import re\n",
    "    from datetime import date, timedelta\n",
    "    day = date.today()\n",
    "    #friday = day - timedelta(days=day.weekday() + 3) + timedelta(days=7)\n",
    "    word = word1 + \" \" + word2\n",
    "    \n",
    "    link_beg = \"https://www.google.com/search?q=%s&source=lnt&tbs=cdr%%3A1%%2Ccd_min%%3A\" % (word)\n",
    "    link_date = \"%s%%2F%s%%2F%s%%2Ccd_max%%3A%s%%2F%s%%2F%s&tbm=&gws_rd=ssl\" % (str(day.month),str(day.day),str(day.year),str(day.month),str(day.day),str(day.year))\n",
    "    url = link_beg + link_date\n",
    "    print(url+\"'\")\n",
    "    print(\"\\t\")\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(r.content)\n",
    "    products = soup.findAll(\"div\", id = \"resultStats\")\n",
    "    result = str(products[0])\n",
    "    results = re.findall(r'\\d+', result)\n",
    "    \n",
    "    number = ''.join([str(i) for i in results])\n",
    "    print(number)\n",
    "\n",
    "    \n",
    "list1 = [\"RB\",\"RBR\",\"RBS\"]\n",
    "list2 = [\"VB\",\"VBD\",\"VBN\",\"VBG\"]\n",
    "list_combn = itertools.product(list1,list2)\n",
    "\n",
    "\n",
    "def so(phrase):\n",
    "    num = hits(phrase,\"excellent\")\n",
    "    #print num\n",
    "    den = hits(phrase,\"poor\")\n",
    "    #print den\n",
    "    ratio = num / den\n",
    "    #print ratio\n",
    "    sop = log(ratio)\n",
    "    return sop\n",
    "\n",
    "\n",
    "def check(newl,spl1):\n",
    "    print(newl)\n",
    "    print(spl1)\n",
    "    for k in range(0,len(newl)):\n",
    "        if(k!=len(newl)-1):\n",
    "            list_new=[]\n",
    "            list_new.append(newl[k])\n",
    "            list_new.append(newl[k+1])\n",
    "            list_new = tuple(list_new)\n",
    "        \n",
    "            if( newl[k]==\"JJ\" and newl[k+1]==\"JJ\" and newl[k+2]!=\"NN\" and newl[k+2]!=\"NNS\"):\n",
    "                return \"\".join(spl1[k])+\" \"+\"\".join(spl1[k+1])\n",
    "                \n",
    "            if( newl[k]==\"JJ\" and newl[k+1]==\"NN\" ) or ( newl[k]==\"JJ\" and newl[k+1]==\"NNS\" ):\n",
    "                return \"\".join(spl1[k])+\" \"+\"\".join(spl1[k+1])\n",
    "                \n",
    "            if( newl[k]==\"NN\" and newl[k+1]==\"JJ\" and newl[k+2]!=\"NN\" and newl[k+2]!=\"NNS\") or ( newl[k]==\"NNS\" and newl[k+1]==\"JJ\" and newl[k+2]!=\"NN\" and newl[k+2]!=\"NNS\"):\n",
    "                return \"\".join(spl1[k])+\" \"+\"\".join(spl1[k+1])\n",
    "                \n",
    "            if( newl[k]==\"RB\" and newl[k+1]==\"JJ\" and newl[k+2]!=\"NN\" and newl[k+2]!=\"NNS\") or ( newl[k]==\"RBR\" and newl[k+1]==\"JJ\" and newl[k+2]!=\"NN\" and newl[k+2]!=\"NNS\") or ( newl[k]==\"RBS\" and newl[k+1]==\"JJ\" and newl[k+2]!=\"NN\" and newl[k+2]!=\"NNS\"):\n",
    "                return \"\".join(spl1[k])+\" \"+\"\".join(spl1[k+1])\n",
    "                \n",
    "            for iter in list_combn:\n",
    "                if(list_new == iter):\n",
    "                    return \"\".join(spl1[k])+\" \"+\"\".join(spl1[k+1])\n",
    "            \n",
    "            \n",
    "\n",
    "def text_pos(raw):\n",
    "    global list,newlist,newlist1,ct\n",
    "    print(\"raw input:\",raw)\n",
    "    spl=raw.split()\n",
    "    print(\"\\n\")\n",
    "    print(\"split version of input:\",spl)\n",
    "    pos=nltk.pos_tag(spl)\n",
    "    print(\"\\n\")\n",
    "    print(\"POS tagged text:\",\"\")\n",
    "    for iter in pos:\n",
    "        print(iter,\"\")\n",
    "    for i in range(0,len(pos)):\n",
    "        if(i!=len(pos)-1):\n",
    "            list.append(pos[i])\n",
    "            list.append(pos[i+1])\n",
    "            t1 = list[0]\n",
    "            t2 = list[1]\n",
    "            newlist.append(t1[1])\n",
    "            newlist.append(t2[1])\n",
    "            list=[]\n",
    "    print(\"\\n\")\n",
    "    print(\"Extracting the tags alone:\",\"\")\n",
    "    print(newlist)\n",
    "    for j in range(0,len(newlist)):\n",
    "        if((j%2!=0) and (j!=len(newlist)-1)):\n",
    "            newlist[j]=0\n",
    "            \n",
    "    newlist = [x for x in newlist if x != 0]\n",
    "    print(\"Checking whether the tags conform to the required pattern...\")\n",
    "    print(\"\\n\")\n",
    "    print(spl)\n",
    "    print(newlist)\n",
    "    print(\"The extracted two-word phrases which satisfy the required pattern are:\")\n",
    "    strr1=check(newlist,spl)\n",
    "    return strr1\n",
    "\n",
    "#print(\"PMI - Pointwise Mutual Information\")\n",
    "#print(\"\\n\")\n",
    "strr = text_pos(\"Nokia is a amazing phone\")\n",
    "#print(strr)\n",
    "#x = so(strr)\n",
    "x = hits(strr)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
